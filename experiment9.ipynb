{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOm6Dxaa2RgYxFu6yTUnj4l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kalyankargouri/ANN/blob/main/experiment9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjyoeAtvDPBu",
        "outputId": "d16d8c6a-431a-47e8-9a38-b8b51c7df1fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Loss = 1329718256.2209\n",
            "Epoch 100: Loss = 24929753.8261\n",
            "Epoch 200: Loss = 3197874.9214\n",
            "Epoch 300: Loss = 2743337.9299\n",
            "Epoch 400: Loss = 2667844.8632\n",
            "Epoch 500: Loss = 2603125.9890\n",
            "Epoch 600: Loss = 2542133.6035\n",
            "Epoch 700: Loss = 2484288.9833\n",
            "Epoch 800: Loss = 2429217.6692\n",
            "Epoch 900: Loss = 2376619.5499\n",
            "\n",
            "Predicted Price (approx):\n",
            "32136.45492584567\n"
          ]
        }
      ],
      "source": [
        "#House price prediction\n",
        "import numpy as np\n",
        "\n",
        "# Sample dataset: [rooms, area (sqft), location index]\n",
        "X = np.array([\n",
        "    [2, 1200, 0.5],\n",
        "    [3, 1500, 0.7],\n",
        "    [4, 1800, 0.9],\n",
        "    [3, 1600, 0.6],\n",
        "    [5, 2000, 1.0]\n",
        "])\n",
        "\n",
        "# Corresponding house prices (in thousands)\n",
        "Y = np.array([[25000], [30000], [40000], [32000], [50000]])\n",
        "\n",
        "# Normalize features\n",
        "X_mean = np.mean(X, axis=0)\n",
        "X_std = np.std(X, axis=0)\n",
        "X = (X - X_mean) / X_std\n",
        "\n",
        "# Normalize Y if using cross-entropy\n",
        "loss_type = 'mse'\n",
        "\n",
        "if loss_type == 'cross_entropy':\n",
        "    Y_min, Y_max = Y.min(), Y.max()\n",
        "    Y_scaled = (Y - Y_min) / (Y_max - Y_min)\n",
        "else:\n",
        "    Y_scaled = Y.copy()\n",
        "\n",
        "# Weight and bias initialization\n",
        "w = np.random.rand(3, 1)\n",
        "b = np.random.rand(1)\n",
        "lr = 0.01\n",
        "epochs = 1000\n",
        "\n",
        "# Activation functions\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "# Loss functions\n",
        "def mse_loss(y_true, y_pred):\n",
        "    return np.mean((y_true - y_pred) ** 2)\n",
        "\n",
        "def cross_entropy_loss(y_true, y_pred):\n",
        "    eps = 1e-15\n",
        "    y_pred = np.clip(y_pred, eps, 1 - eps)\n",
        "    return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    z = np.dot(X, w) + b\n",
        "    # y_pred = sigmoid(z)\n",
        "\n",
        "\n",
        "    if loss_type == 'mse':\n",
        "        y_pred = z;\n",
        "        loss = mse_loss(Y_scaled, y_pred)\n",
        "        d_loss = 2 * (y_pred - Y_scaled) / len(Y)\n",
        "    elif loss_type == 'cross_entropy':\n",
        "        loss = cross_entropy_loss(Y_scaled, y_pred)\n",
        "        d_loss = (y_pred - Y_scaled) * sigmoid_derivative(y_pred)\n",
        "\n",
        "    # Gradients\n",
        "    dw = np.dot(X.T, d_loss)\n",
        "    db = np.sum(d_loss, axis=0)\n",
        "\n",
        "    # Update weights\n",
        "    w -= lr * dw\n",
        "    b -= lr * db\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"Epoch {epoch}: Loss = {loss:.4f}\")\n",
        "\n",
        "# Prediction\n",
        "new_input = np.array([[3, 1500, 0.7]])\n",
        "new_input = (new_input - X_mean) / X_std\n",
        "prediction = np.dot(new_input, w) + b\n",
        "\n",
        "\n",
        "print(\"\\nPredicted Price (approx):\")\n",
        "print(prediction[0][0])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#email spam or not\n",
        "import numpy as np\n",
        "\n",
        "# Sample features: [keyword_freq, sender_score, email_length]\n",
        "X = np.array([\n",
        "    [3, 0.1, 200],  # Not spam\n",
        "    [10, 0.9, 100], # Spam\n",
        "    [1, 0.2, 150],  # Not spam\n",
        "    [7, 0.8, 120],  # Spam\n",
        "])\n",
        "\n",
        "# Labels\n",
        "Y = np.array([[0], [1], [0], [1]])\n",
        "\n",
        "# Normalize features (optional but helps with learning)\n",
        "X = (X - np.mean(X, axis=0)) / np.std(X, axis=0)\n",
        "\n",
        "W = np.random.rand(3, 1)\n",
        "b = np.random.rand(1)\n",
        "lr = 0.1\n",
        "epochs = 1000\n",
        "loss_history = []\n",
        "loss_type = 'cross-entropy'\n",
        "\n",
        "# Activation function\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "# Loss functions\n",
        "def mse_loss(y_true, y_pred):\n",
        "    return np.mean((y_true - y_pred) ** 2)\n",
        "\n",
        "def cross_entropy_loss(y_true, y_pred):\n",
        "    eps = 1e-15\n",
        "    y_pred = np.clip(y_pred, eps, 1 - eps)\n",
        "    return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
        "\n",
        "# Training function\n",
        "for epoch in range(epochs):\n",
        "    z = np.dot(X, W) + b\n",
        "    y_pred = sigmoid(z)\n",
        "\n",
        "    # Select loss function\n",
        "    if loss_type == 'mse':\n",
        "        loss = mse_loss(Y, y_pred)\n",
        "        d_loss = 2 * (y_pred - Y) * sigmoid_derivative(y_pred)\n",
        "    elif loss_type == 'cross-entropy':\n",
        "        loss = cross_entropy_loss(Y, y_pred)\n",
        "        d_loss = (y_pred - Y) * sigmoid_derivative(y_pred)\n",
        "\n",
        "    # Backpropagation\n",
        "    dw = np.dot(X.T, d_loss)\n",
        "    db = np.sum(d_loss)\n",
        "\n",
        "    W -= lr * dw\n",
        "    b -= lr * db\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"[{loss_type.upper()}] Epoch {epoch}, Loss: {loss:.4f}\")\n",
        "    loss_history.append(loss)\n",
        "\n",
        "output = sigmoid(np.dot(X, W) + b)\n",
        "print(\"\\nFinal Predictions:\")\n",
        "print(output.round())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxJpmX0BDWF4",
        "outputId": "d073f0cb-83e1-4271-c8f2-66b3acb77546"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CROSS-ENTROPY] Epoch 0, Loss: 0.6552\n",
            "[CROSS-ENTROPY] Epoch 100, Loss: 0.0839\n",
            "[CROSS-ENTROPY] Epoch 200, Loss: 0.0573\n",
            "[CROSS-ENTROPY] Epoch 300, Loss: 0.0461\n",
            "[CROSS-ENTROPY] Epoch 400, Loss: 0.0395\n",
            "[CROSS-ENTROPY] Epoch 500, Loss: 0.0351\n",
            "[CROSS-ENTROPY] Epoch 600, Loss: 0.0319\n",
            "[CROSS-ENTROPY] Epoch 700, Loss: 0.0294\n",
            "[CROSS-ENTROPY] Epoch 800, Loss: 0.0274\n",
            "[CROSS-ENTROPY] Epoch 900, Loss: 0.0257\n",
            "\n",
            "Final Predictions:\n",
            "[[0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#student placement prediction\n",
        "import numpy as np\n",
        "\n",
        "# Sample Data: [10th%, 12th%, CGPA, IQ]\n",
        "X = np.array([\n",
        "    [85, 80, 8.0, 110],\n",
        "    [70, 65, 6.5, 95],\n",
        "    [90, 88, 9.0, 120],\n",
        "    [60, 58, 5.8, 85],\n",
        "    [75, 70, 7.2, 100]\n",
        "])\n",
        "\n",
        "# Labels: 1 = Placed, 0 = Not Placed\n",
        "Y = np.array([[1], [0], [1], [0], [1]])\n",
        "\n",
        "# Normalize features\n",
        "X_mean = np.mean(X, axis=0)\n",
        "X_std = np.std(X, axis=0)\n",
        "X = (X - X_mean) / X_std\n",
        "\n",
        "# Initialize weights and bias\n",
        "w = np.random.rand(4, 1)\n",
        "b = np.random.rand(1)\n",
        "lr = 0.01\n",
        "epochs = 1000\n",
        "loss_type = 'cross-entropy'\n",
        "\n",
        "# Activation function\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "# Loss functions\n",
        "def mse_loss(y_true, y_pred):\n",
        "    return np.mean((y_true - y_pred) ** 2)\n",
        "\n",
        "def cross_entropy_loss(y_true, y_pred):\n",
        "    eps = 1e-15\n",
        "    y_pred = np.clip(y_pred, eps, 1 - eps)\n",
        "    return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
        "\n",
        "# Training function\n",
        "for epoch in range(epochs):\n",
        "    z = np.dot(X, w) + b\n",
        "    y_pred = sigmoid(z)\n",
        "\n",
        "    # Select loss function\n",
        "    if loss_type == 'mse':\n",
        "        loss = mse_loss(Y, y_pred)\n",
        "        d_loss = 2 * (y_pred - Y) * sigmoid_derivative(y_pred)\n",
        "    elif loss_type == 'cross-entropy':\n",
        "        loss = cross_entropy_loss(Y, y_pred)\n",
        "        d_loss = (y_pred - Y) * sigmoid_derivative(y_pred)\n",
        "\n",
        "    # Backpropagation\n",
        "    dw = np.dot(X.T, d_loss)\n",
        "    db = np.sum(d_loss)\n",
        "\n",
        "    w -= lr * dw\n",
        "    b -= lr * db\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\" Epoch {epoch}, Loss: {loss:.4f}\")\n",
        "\n",
        "output = sigmoid(np.dot(X, w) + b)\n",
        "print(\"\\nFinal Predictions:\")\n",
        "print(output.round())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izzmMw2EDpy3",
        "outputId": "c63442d1-d174-4fb3-f271-2936c5140de2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Epoch 0, Loss: 0.4760\n",
            " Epoch 100, Loss: 0.3150\n",
            " Epoch 200, Loss: 0.2671\n",
            " Epoch 300, Loss: 0.2424\n",
            " Epoch 400, Loss: 0.2262\n",
            " Epoch 500, Loss: 0.2142\n",
            " Epoch 600, Loss: 0.2046\n",
            " Epoch 700, Loss: 0.1966\n",
            " Epoch 800, Loss: 0.1897\n",
            " Epoch 900, Loss: 0.1836\n",
            "\n",
            "Final Predictions:\n",
            "[[1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample data: [Today_Temp, Humidity, WindSpeed]\n",
        "X = np.array([\n",
        "    [30, 70, 10],\n",
        "    [32, 65, 12],\n",
        "    [31, 72, 9],\n",
        "    [29, 75, 8],\n",
        "    [33, 60, 11]\n",
        "])\n",
        "\n",
        "# Target: Next day temperature\n",
        "Y = np.array([[31], [33], [32], [30], [34]])\n",
        "\n",
        "# Normalize input features\n",
        "X_mean = np.mean(X, axis=0)\n",
        "X_std = np.std(X, axis=0)\n",
        "X = (X - X_mean) / X_std\n",
        "\n",
        "loss_type = 'mse'\n",
        "\n",
        "if loss_type == 'cross_entropy':\n",
        "    Y_min, Y_max = Y.min(), Y.max()\n",
        "    Y_scaled = (Y - Y_min) / (Y_max - Y_min)\n",
        "else:\n",
        "    Y_scaled = Y.copy()\n",
        "\n",
        "# Weight and bias initialization\n",
        "w = np.random.rand(3, 1)\n",
        "b = np.random.rand(1)\n",
        "lr = 0.01\n",
        "epochs = 1000\n",
        "\n",
        "# Activation functions\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "# Loss functions\n",
        "def mse_loss(y_true, y_pred):\n",
        "    return np.mean((y_true - y_pred) ** 2)\n",
        "\n",
        "def cross_entropy_loss(y_true, y_pred):\n",
        "    eps = 1e-15\n",
        "    y_pred = np.clip(y_pred, eps, 1 - eps)\n",
        "    return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    z = np.dot(X, w) + b\n",
        "    # y_pred = sigmoid(z)\n",
        "\n",
        "\n",
        "    if loss_type == 'mse':\n",
        "        y_pred = z;\n",
        "        loss = mse_loss(Y_scaled, y_pred)\n",
        "        d_loss = 2 * (y_pred - Y_scaled) / len(Y)\n",
        "    elif loss_type == 'cross_entropy':\n",
        "        loss = cross_entropy_loss(Y_scaled, y_pred)\n",
        "        d_loss = (y_pred - Y_scaled) * sigmoid_derivative(y_pred)\n",
        "\n",
        "    # Gradients\n",
        "    dw = np.dot(X.T, d_loss)\n",
        "    db = np.sum(d_loss, axis=0)\n",
        "\n",
        "    # Update weights\n",
        "    w -= lr * dw\n",
        "    b -= lr * db\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"Epoch {epoch}: Loss = {loss:.4f}\")\n",
        "\n",
        "#Predict next day temperature\n",
        "new_data = np.array([[31, 68, 10]])  # today's temp, humidity, wind speed\n",
        "new_data = (new_data - X_mean) / X_std\n",
        "prediction = np.dot(new_data, w) + b\n",
        "\n",
        "print(\"\\nForecasted Temperature (°C):\")\n",
        "print(prediction[0][0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAiGRAitEPbY",
        "outputId": "e19c740e-36e9-4abe-c073-b8f3985214e1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Loss = 963.4791\n",
            "Epoch 100: Loss = 16.9586\n",
            "Epoch 200: Loss = 0.3202\n",
            "Epoch 300: Loss = 0.0183\n",
            "Epoch 400: Loss = 0.0084\n",
            "Epoch 500: Loss = 0.0056\n",
            "Epoch 600: Loss = 0.0041\n",
            "Epoch 700: Loss = 0.0030\n",
            "Epoch 800: Loss = 0.0023\n",
            "Epoch 900: Loss = 0.0018\n",
            "\n",
            "Forecasted Temperature (°C):\n",
            "31.99134770849704\n"
          ]
        }
      ]
    }
  ]
}